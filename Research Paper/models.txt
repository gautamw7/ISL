# 1. GRU Model 
'''
            x = GRU(384, return_sequences=True)(inputs)   
            x = LayerNormalization()(x)
            x = Dropout(dropout[0])(x)
            
            x = GRU(256, return_sequences=True)(x)
            x = LayerNormalization()(x)
            x = Dropout(dropout[1])(x)
            
            x = GRU(128, return_sequences=True)(x)
            x = LayerNormalization()(x)
            
            x = attention_block(x)  # Compresses to (batch_size, features)
            
            x = Dense(64, activation='relu')(x)
            x = Dropout(dropout[2])(x)
            outputs = Dense(num_classes, activation='softmax')(x)
            
            model = Model(inputs, outputs)
''' 
# 2. Bi-Dir GRU  
'''
            x = Bidirectional(GRU(384, return_sequences=True))(inputs)
            x = LayerNormalization()(x)
            x = Dropout(dropout[0])(x)
            
            x = Bidirectional(GRU(256, return_sequences=True))(x)
            x = LayerNormalization()(x)
            x = Dropout(dropout[1])(x)
            
            x = Bidirectional(GRU(128, return_sequences=True))(x)
            x = LayerNormalization()(x)
            
            x = attention_block(x)  # <- attention compresses to (batch_size, features)
            
            x = Dense(64, activation='relu')(x)
            x = Dropout(dropout[2])(x)
            outputs = Dense(num_classes, activation='softmax')(x)

            model = Model(inputs, outputs)
''' 
# 3. LSTM 
'''

            x = LSTM(384, return_sequences=True)(inputs)
            x = LayerNormalization()(x)
            x = Dropout(dropout[0])(x)
            
            x = LSTM(256, return_sequences=True)(x)
            x = LayerNormalization()(x)
            x = Dropout(dropout[1])(x)
            
            x = LSTM(128, return_sequences=True)(x)
            x = LayerNormalization()(x)
            
            x = attention_block(x)  # Compresses to (batch_size, features)
            
            x = Dense(64, activation='relu')(x)
            x = Dropout(dropout[2])(x)
            outputs = Dense(num_classes, activation='softmax')(x)
            
            model = Model(inputs, outputs)
'''
# 4. Bi-LSTM  # Take model summary - not done
'''
            x = Bidirectional(LSTM(384, return_sequences=True))(inputs)
            x = LayerNormalization()(x)
            x = Dropout(dropout[0])(x)
            
            x = Bidirectional(LSTM(256, return_sequences=True))(x)
            x = LayerNormalization()(x)
            x = Dropout(dropout[1])(x)
            
            x = Bidirectional(LSTM(128, return_sequences=True))(x)
            x = LayerNormalization()(x)
            
            x = attention_block(x)  # Compresses to (batch_size, features)
            
            x = Dense(64, activation='relu')(x)
            x = Dropout(dropout[2])(x)
            outputs = Dense(num_classes, activation='softmax')(x)
            
            model = Model(inputs, outputs)
'''